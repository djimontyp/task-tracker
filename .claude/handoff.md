# Handoff: Pulse Radar

**–ì—ñ–ª–∫–∞:** `006-knowledge-discovery`
**–û–Ω–æ–≤–ª–µ–Ω–æ:** 2025-12-28 18:30

---

## –©–æ –∑—Ä–æ–±–ª–µ–Ω–æ

### 1. Core Flow Verification ‚úÖ

```
Telegram webhook ‚Üí Message ‚Üí AI parsing ‚Üí Atoms/Topics ‚Üí UI
       ‚úÖ            ‚úÖ          ‚úÖ           ‚úÖ        ‚úÖ
```

- 4 Atoms, 4 Topics, 2 Links —Å—Ç–≤–æ—Ä–µ–Ω–æ —á–µ—Ä–µ–∑ LLM
- UUID serialization bug –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ

### 2. Unified Scoring Config ‚úÖ (Calibrated)

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –°—Ç–∞—Ä–µ | –ù–æ–≤–µ | –ü—Ä–∏—á–∏–Ω–∞ |
|----------|-------|------|---------|
| noise_threshold | 0.25 | **0.30** | "–û–∫", "üëç" (score ~0.28) –º–∞—é—Ç—å –±—É—Ç–∏ noise |
| signal_threshold | 0.65 | **0.60** | "–ö—Ä–∏—Ç–∏—á–Ω–∏–π –±–∞–≥" (score 0.63) –º–∞—î –±—É—Ç–∏ signal |

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** 2 noise, 1 signal, 20 weak_signal

### 3. RAG Integration ‚úÖ (NEW!)

**Phase 1: Activate RAG** ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–æ!

```
–ë–£–õ–û:
  save_msg ‚Üí score ‚Üí extract ‚Üí embed (–∑–∞–Ω–∞–¥—Ç–æ –ø—ñ–∑–Ω–æ!)
                        ‚Üì
                    RAG ‚ùå –ø–æ—Ä–æ–∂–Ω—ñ–π

–°–¢–ê–õ–û:
  save_msg ‚Üí score ‚Üí embed ‚Üí extract
                        ‚Üì      ‚Üì
                      –≥–æ—Ç–æ–≤—ñ   RAG ‚úÖ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Å—Ö–æ–∂—ñ
```

**–ó–º—ñ–Ω–∏:**

| –§–∞–π–ª | –©–æ –∑—Ä–æ–±–ª–µ–Ω–æ |
|------|-------------|
| `scoring.py` | –î–æ–¥–∞–Ω–æ embedding –ø—ñ—Å–ª—è scoring –¥–ª—è RAG-ready search |
| `knowledge.py` | –í–∏–¥–∞–ª–µ–Ω–æ –¥—É–±–ª—é–≤–∞–Ω–Ω—è embed_messages, –¥–æ–¥–∞–Ω–æ RAGContextBuilder |
| `knowledge_orchestrator.py` | Inject RAG context —É extract_knowledge() |

**–Ø–∫ –ø—Ä–∞—Ü—é—î:**
1. Message scored ‚Üí –æ–¥—Ä–∞–∑—É embed for RAG
2. –ü—Ä–∏ extraction ‚Üí RAGContextBuilder.build_context() —à—É–∫–∞—î:
   - Similar proposals (past approved)
   - Relevant atoms (knowledge base)
   - Related messages (history)
3. Context inject —É LLM prompt –ø–µ—Ä–µ–¥ extraction

---

## –©–æ –¥–∞–ª—ñ

### Phase 2: Improve Batching (P1)

- [ ] Thread detection (reply_to_message_id, time gaps)
- [ ] Group by channel before batching
- [ ] Language pre-filtering (uk/en separate batches)

### Phase 3: Reliability (P1)

- [ ] Add retry with exponential backoff
- [ ] Dead letter queue for failed tasks
- [ ] Deduplication before save (vector similarity > 0.9)

### Phase 4: Cost Optimization (P2)

- [ ] Two-tier model selection (cheap for classification, quality for extraction)

---

## –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

```bash
# –°–µ—Ä–≤—ñ—Å–∏ –≤–∂–µ running:
docker ps | grep task-tracker

# –Ø–∫—â–æ –Ω–µ running:
just services

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ RAG –≤ –ª–æ–≥–∞—Ö:
docker logs -f task-tracker-worker 2>&1 | grep -i "rag\|context"

# Trigger extraction manually:
curl -X POST http://localhost/api/v1/analysis/extract \
  -H "Content-Type: application/json" \
  -d '{"period_type": "last_24h"}'
```

---

## –ö–ª—é—á–æ–≤—ñ —Ñ–∞–π–ª–∏

| –§–∞–π–ª | –©–æ |
|------|-----|
| `backend/app/tasks/scoring.py` | Embed –ø—ñ—Å–ª—è scoring |
| `backend/app/tasks/knowledge.py` | RAGContextBuilder integration |
| `backend/app/services/knowledge/knowledge_orchestrator.py` | RAG injection —É prompt |
| `backend/app/services/rag_context_builder.py` | Semantic context builder |
| `backend/app/config/ai_config.py` | Thresholds (0.30/0.60) |
| `.obsidian-docs/–ø–ª–∞–Ω–∏/extraction-pipeline-improvements.md` | Full roadmap |

---

## –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

### E2E —Ç–µ—Å—Ç–∏ (8 tests, all pass)

```bash
cd frontend && npx playwright test tests/e2e/knowledge-extraction.spec.ts --project=chromium
```

### Worker logs

```bash
docker logs -f task-tracker-worker 2>&1 | grep -i "rag\|context"

# –ú–∞—î –±—É—Ç–∏:
# "Building RAG context for extraction..."
# "RAG context built: X proposals, Y atoms, Z messages"
```

---

## Commits

| Hash | Description |
|------|-------------|
| `4ca13e7` | feat(extraction): activate RAG context in knowledge extraction pipeline |
| `5289ff4` | fix(rag): use asyncpg raw connection for pgvector queries |
