# ADR-003: Перехід на AI Importance Scoring

**Дата:** 2026-01-08
**Статус:** Прийнято

## Контекст

У системі **Pulse Radar** існує механізм оцінки важливості повідомлень (`ImportanceScorer`), який використовується для фільтрації шуму (Noise) та виділення сигналів (Signals) перед етапом екстракції знань.

Попередня реалізація базувалася на **евристичному алгоритмі** (Regex, Keywords, Meta-data rules), який мав суттєві недоліки для нашого юзкейсу:

1.  **Мовний бар'єр**: Алгоритм був жорстко налаштований на англійські ключові слова (`bug`, `critical`), що робило його недієздатним для україномовних чатів.
2.  **Штраф за історію (Time Decay)**: Алгоритм автоматично занижував оцінку старих повідомлень (> 7 днів), що блокувало можливість ефективного імпорту та аналізу історичних архівів.
3.  **Відсутність контексту**: Аналіз базувався на поверхневих ознаках (довжина, посилання), а не на семантичному змісті.
4.  **Cold Start**: Для нових авторів (без історії) оцінка була дефолтною (0.5), що не дозволяло одразу виділяти експертний контент.

## Рішення

Ми відмовляємося від евристичного підходу (`Heuristic Scorer`) на користь **AI Scoring** (`AI Judge`).

Ми впроваджуємо новий сервіс `LLMImportanceScorer`, який:
1.  Використовує LLM (через існуючий `ProviderResolver`) для оцінки кожного повідомлення.
2.  Приймає рішення на основі **суті** повідомлення, а не формальних ознак.
3.  Ігнорує дату створення повідомлення при оцінці його *інформаційної цінності*.

### Архітектурний вибір: LLM vs Vectors

Розглядалося два варіанти "розумного" скорингу:
*   **Варіант А (Обраний): LLM Judge**. Прямий запит до LLM: *"Оціни важливість цього повідомлення від 0 до 1"*.
    *   *Плюс:* Висока точність, розуміння сарказму, сленгу, контексту.
    *   *Мінус:* Вартість (токени) та час виконання.
*   **Варіант Б (Відхилений): Vector Similarity**. Порівняння вектора повідомлення з еталонним вектором "Важливого повідомлення".
    *   *Причина відмови:* Вектори добре шукають *схожість* (Similarity), але погано оцінюють *суть* (Reasoning). Фрази "Все впало" і "Все працює" можуть бути векторно близькими, але діаметрально протилежними за важливістю. Векторний пошук залишається для RAG (Context Retrieval).

## Економічне обґрунтування (ROI)

Хоча AI Scoring дорожчий за Regex, він виступає як **Smart Filter**:
*   **Input**: 1000 "сирих" повідомлень.
*   **Process**: AI Scorer (дешева/швидка модель) відсіює 950 повідомлень шуму ("ок", "дякую", "буду").
*   **Output**: 50 якісних "сигналів", які йдуть на (дорогу) глибоку екстракцію знань.

Це запобігає забрудненню Бази Знань сміттям і економить ресурси на етапі екстракції.

## Технічна реалізація

1.  **Clean Slate**: Старий код `importance_scorer.py` видаляється (або переміщується в legacy), щоб не створювати технічний борг.
2.  **Local First**: Архітектура підтримує локальні моделі (Ollama, LM Studio) через OpenAI-compatible API, що дозволяє використовувати наявне залізо (RTX 4070Ti Super) без витрат на хмарні API.
3.  **Prompt Engineering**: Промпт для скорингу має бути коротким, повертати JSON з полями `score` (0.0-1.0) та `classification` (reasoning).

## Наслідки

Positives:
*   Підтримка будь-якої мови (UA/EN) "з коробки".
*   Коректна робота з історичними даними.
*   Висока якість "Smart Suggestions" у UI.

Negatives:
*   Збільшення часу обробки повідомлення (секунди замість мілісекунд). Це вирішується асинхронною обробкою (`background tasks`).
*   Залежність від доступності LLM провайдера.
