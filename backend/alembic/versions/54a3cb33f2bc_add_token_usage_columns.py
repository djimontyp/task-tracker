"""add_token_usage_columns

Revision ID: 54a3cb33f2bc
Revises: b2c3d4e5f6a7
Create Date: 2026-01-09 02:32:51.508284

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '54a3cb33f2bc'
down_revision: Union[str, Sequence[str], None] = 'b2c3d4e5f6a7'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('tasks')
    op.drop_table('classification_experiments')
    op.drop_index(op.f('idx_atoms_fts'), table_name='atoms', postgresql_using='gin')
    op.alter_column('classification_feedback', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('classification_feedback', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_constraint(op.f('classification_feedback_message_id_fkey'), 'classification_feedback', type_='foreignkey')
    op.create_foreign_key(None, 'classification_feedback', 'messages', ['message_id'], ['id'])
    op.add_column('knowledge_extraction_runs', sa.Column('tokens_prompt', sa.Integer(), nullable=True))
    op.add_column('knowledge_extraction_runs', sa.Column('tokens_completion', sa.Integer(), nullable=True))
    op.add_column('knowledge_extraction_runs', sa.Column('tokens_total', sa.Integer(), nullable=True))
    op.alter_column('message_history', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('message_history', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_constraint(op.f('message_history_message_id_fkey'), 'message_history', type_='foreignkey')
    op.create_foreign_key(None, 'message_history', 'messages', ['message_id'], ['id'])
    op.alter_column('messages', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=None,
               existing_nullable=True)
    op.drop_index(op.f('ix_messages_status'), table_name='messages')
    op.alter_column('project_configs', 'language',
               existing_type=sa.VARCHAR(length=10),
               server_default=None,
               existing_nullable=False)
    op.alter_column('topics', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_nullable=False)
    op.alter_column('users', 'ui_language',
               existing_type=sa.VARCHAR(length=10),
               server_default=None,
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('users', 'ui_language',
               existing_type=sa.VARCHAR(length=10),
               server_default=sa.text("'uk'::character varying"),
               existing_nullable=False)
    op.alter_column('topics', 'is_active',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('true'),
               existing_nullable=False)
    op.alter_column('project_configs', 'language',
               existing_type=sa.VARCHAR(length=10),
               server_default=sa.text("'uk'::character varying"),
               existing_nullable=False)
    op.create_index(op.f('ix_messages_status'), 'messages', ['status'], unique=False)
    op.alter_column('messages', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=sa.text("'pending'::character varying"),
               existing_nullable=True)
    op.drop_constraint(None, 'message_history', type_='foreignkey')
    op.create_foreign_key(op.f('message_history_message_id_fkey'), 'message_history', 'messages', ['message_id'], ['id'], ondelete='CASCADE')
    op.alter_column('message_history', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('message_history', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_column('knowledge_extraction_runs', 'tokens_total')
    op.drop_column('knowledge_extraction_runs', 'tokens_completion')
    op.drop_column('knowledge_extraction_runs', 'tokens_prompt')
    op.drop_constraint(None, 'classification_feedback', type_='foreignkey')
    op.create_foreign_key(op.f('classification_feedback_message_id_fkey'), 'classification_feedback', 'messages', ['message_id'], ['id'], ondelete='CASCADE')
    op.alter_column('classification_feedback', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('classification_feedback', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.create_index(op.f('idx_atoms_fts'), 'atoms', [sa.literal_column("to_tsvector('simple'::regconfig, (title::text || ' '::text) || content)")], unique=False, postgresql_using='gin')
    op.create_table('classification_experiments',
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('provider_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('model_name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('status', postgresql.ENUM('pending', 'running', 'completed', 'failed', name='experimentstatus'), autoincrement=False, nullable=False),
    sa.Column('message_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('topics_snapshot', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('avg_confidence', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('avg_execution_time_ms', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('confusion_matrix', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('classification_results', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['provider_id'], ['llm_providers.id'], name=op.f('classification_experiments_provider_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('classification_experiments_pkey'))
    )
    op.create_table('tasks',
    sa.Column('title', sa.VARCHAR(length=200), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('category', postgresql.ENUM('bug', 'feature', 'improvement', 'question', 'chore', name='taskcategory'), autoincrement=False, nullable=False),
    sa.Column('priority', postgresql.ENUM('low', 'medium', 'high', 'critical', name='taskpriority'), autoincrement=False, nullable=False),
    sa.Column('status', postgresql.ENUM('open', 'in_progress', 'completed', 'closed', name='taskstatus'), autoincrement=False, nullable=False),
    sa.Column('classification_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('ai_generated', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('confidence_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('source_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('source_message_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('assigned_to', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_by', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['assigned_to'], ['users.id'], name=op.f('tasks_assigned_to_fkey')),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], name=op.f('tasks_created_by_fkey')),
    sa.ForeignKeyConstraint(['source_id'], ['sources.id'], name=op.f('tasks_source_id_fkey')),
    sa.ForeignKeyConstraint(['source_message_id'], ['messages.id'], name=op.f('tasks_source_message_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('tasks_pkey'))
    )
    # ### end Alembic commands ###
